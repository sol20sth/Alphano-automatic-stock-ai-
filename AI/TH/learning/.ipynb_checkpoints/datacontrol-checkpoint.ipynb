{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: finance-datareader in c:\\python37\\lib\\site-packages (0.9.50)\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\python37\\lib\\site-packages (from finance-datareader) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\python37\\lib\\site-packages (from finance-datareader) (2.31.0)\n",
      "Requirement already satisfied: requests-file in c:\\python37\\lib\\site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: lxml in c:\\python37\\lib\\site-packages (from finance-datareader) (4.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\python37\\lib\\site-packages (from finance-datareader) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\python37\\lib\\site-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python37\\lib\\site-packages (from pandas>=0.19.2->finance-datareader) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python37\\lib\\site-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python37\\lib\\site-packages (from requests>=2.3.0->finance-datareader) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python37\\lib\\site-packages (from requests>=2.3.0->finance-datareader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests>=2.3.0->finance-datareader) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests>=2.3.0->finance-datareader) (2023.7.22)\n",
      "Requirement already satisfied: six in c:\\python37\\lib\\site-packages (from requests-file->finance-datareader) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\python37\\lib\\site-packages (from tqdm->finance-datareader) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close    Volume    Change  \\\n",
      "Date                                                                     \n",
      "2015-01-29  0.333783  0.323470  0.317992  0.309362  0.084334 -0.014173   \n",
      "2015-01-30  0.313554  0.301950  0.297071  0.284939  0.166516 -0.028754   \n",
      "2015-02-02  0.289278  0.279085  0.290098  0.280868  0.077978 -0.004934   \n",
      "2015-02-03  0.285233  0.277740  0.290098  0.278155  0.068692 -0.003306   \n",
      "2015-02-04  0.289278  0.287155  0.295676  0.291723  0.089672  0.016584   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2019-12-23  0.448415  0.436449  0.454672  0.443691  0.008099  0.000000   \n",
      "2019-12-24  0.447067  0.437794  0.454672  0.435550  0.002450 -0.008276   \n",
      "2019-12-26  0.440324  0.431069  0.444909  0.427408  0.025861 -0.008345   \n",
      "2019-12-27  0.430883  0.429724  0.443515  0.434193  0.045281  0.007013   \n",
      "2019-12-30  0.437626  0.431069  0.450488  0.438263  0.012101  0.004178   \n",
      "\n",
      "                 ma5      ma10      ma20       rsi        %K        %D  \\\n",
      "Date                                                                     \n",
      "2015-01-29  0.317660  0.303979  0.295075  0.611967  0.638298  0.833215   \n",
      "2015-01-30  0.314302  0.303979  0.296523  0.490522  0.255319  0.579174   \n",
      "2015-02-02  0.307865  0.303555  0.298042  0.504711  0.191489  0.361425   \n",
      "2015-02-03  0.296669  0.303272  0.298187  0.458144  0.148936  0.194484   \n",
      "2015-02-04  0.290512  0.305110  0.299128  0.580974  0.361702  0.230776   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2019-12-23  0.449762  0.447593  0.437783  0.764922  0.863636  0.875115   \n",
      "2019-12-24  0.448363  0.448583  0.438506  0.751146  0.727273  0.828596   \n",
      "2019-12-26  0.445004  0.448724  0.438362  0.677675  0.590909  0.735558   \n",
      "2019-12-27  0.443045  0.448866  0.438941  0.698547  0.704545  0.681286   \n",
      "2019-12-30  0.441926  0.448724  0.440533  0.857553  0.743590  0.686852   \n",
      "\n",
      "            bb_upper    bb_sma  bb_lower  volume_ma5  momentum  high_low_diff  \n",
      "Date                                                                           \n",
      "2015-01-29  0.290580  0.295075  0.296088    0.168960  0.523207       0.168317  \n",
      "2015-01-30  0.288728  0.296523  0.301039    0.224289  0.438819       0.158416  \n",
      "2015-02-02  0.285323  0.298042  0.307822    0.234021  0.392405       0.039604  \n",
      "2015-02-03  0.285130  0.298187  0.308326    0.209408  0.320675       0.029703  \n",
      "2015-02-04  0.284480  0.299128  0.310944    0.202179  0.396624       0.059406  \n",
      "...              ...       ...       ...         ...       ...            ...  \n",
      "2019-12-23  0.413154  0.437783  0.453319    0.035257  0.510549       0.029703  \n",
      "2019-12-24  0.414060  0.438506  0.453808    0.018695  0.468354       0.039604  \n",
      "2019-12-26  0.413884  0.438362  0.453705    0.016783  0.438819       0.059406  \n",
      "2019-12-27  0.414570  0.438941  0.454138    0.030639  0.459916       0.059406  \n",
      "2019-12-30  0.415054  0.440533  0.456850    0.022182  0.472574       0.019802  \n",
      "\n",
      "[13178 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, BatchNormalization, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 주식 데이터 불러오기\n",
    "stock_code = '066570'  # 주식 코드 (066570 주식)\n",
    "start_date = '2015-01-01'  # 데이터 수집 시작 날짜\n",
    "end_date = '2019-12-31'   # 데이터 수집 종료 날짜\n",
    "stock_data = fdr.DataReader(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# 5일 이동평균\n",
    "stock_data['ma5'] = stock_data['Close'].rolling(window=5).mean()\n",
    "\n",
    "# 10일 이동평균\n",
    "stock_data['ma10'] = stock_data['Close'].rolling(window=10).mean()\n",
    "\n",
    "# 20일 이동평균\n",
    "stock_data['ma20'] = stock_data['Close'].rolling(window=20).mean()\n",
    "\n",
    "# RSI 계산을 위한 함수\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data['Close'].diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi\n",
    "\n",
    "# 14일 RSI\n",
    "stock_data['rsi'] = calculate_rsi(stock_data)\n",
    "\n",
    "# %K 계산을 위한 함수\n",
    "def calculate_stochastic_k(data, period=14):\n",
    "    lowest_low = data['Low'].rolling(window=period).min()\n",
    "    highest_high = data['High'].rolling(window=period).max()\n",
    "    stochastic_k = (data['Close'] - lowest_low) / (highest_high - lowest_low) * 100\n",
    "    \n",
    "    return stochastic_k\n",
    "\n",
    "# %D 계산을 위한 함수\n",
    "def calculate_stochastic_d(data, period=3):\n",
    "    stochastic_k = calculate_stochastic_k(data)\n",
    "    stochastic_d = stochastic_k.rolling(window=period).mean()\n",
    "    \n",
    "    return stochastic_d\n",
    "\n",
    "# 주요 값 추가\n",
    "stock_data['%K'] = calculate_stochastic_k(stock_data)\n",
    "stock_data['%D'] = calculate_stochastic_d(stock_data)\n",
    "\n",
    "# 볼린저 밴드 계산을 위한 함수\n",
    "def calculate_bollinger_bands(data, window=20):\n",
    "    sma = data['Close'].rolling(window=window).mean()\n",
    "    rolling_std = data['Close'].rolling(window=window).std()\n",
    "\n",
    "    upper_band = sma + (rolling_std * 2)\n",
    "    lower_band = sma - (rolling_std * 2)\n",
    "\n",
    "    return upper_band, sma, lower_band\n",
    "\n",
    "# 볼린저 밴드 값 추가\n",
    "stock_data['bb_upper'], stock_data['bb_sma'], stock_data['bb_lower'] = calculate_bollinger_bands(stock_data)\n",
    "\n",
    "# 거래량 이동평균\n",
    "stock_data['volume_ma5'] = stock_data['Volume'].rolling(window=5).mean()\n",
    "\n",
    "# 모멘텀 (Close 가격의 5일 차)\n",
    "stock_data['momentum'] = stock_data['Close'].diff(5)\n",
    "\n",
    "# 최고가와 최저가 차이\n",
    "stock_data['high_low_diff'] = stock_data['High'] - stock_data['Low']\n",
    "stock_data.dropna(inplace=True)\n",
    "# MinMax 스케일링을 위한 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 정규화할 컬럼 선택 (예: 종가, 시작가, 거래량제외, 최고가, 최저가, 이동평균, RSI, %K, %D, 볼린저 밴드, 거래량 이동평균, 모멘텀, 최고가와 최저가 차이)\n",
    "columns_to_normalize = ['Close', 'Open', 'High', 'Low', 'ma5', 'ma10', 'ma20', 'rsi', '%K', '%D', 'bb_upper', 'bb_sma', 'bb_lower', 'volume_ma5', 'momentum', 'high_low_diff']\n",
    "\n",
    "# 선택한 컬럼을 정규화\n",
    "stock_data[columns_to_normalize] = scaler.fit_transform(stock_data[columns_to_normalize])\n",
    "\n",
    "# 거래량이 10억 이상인 행 찾기\n",
    "high_volume_rows = stock_data[stock_data['Volume'] >= 20000]\n",
    "\n",
    "# 찾은 행과 그 앞의 10개 행 선택\n",
    "selected_indices = []\n",
    "for index in high_volume_rows.index:\n",
    "    index_loc = stock_data.index.get_loc(index)\n",
    "    if index_loc >= 10:  # 10 이전의 행이 있는지 확인\n",
    "        selected_indices.extend(list(range(index_loc - 10, index_loc + 1)))\n",
    "\n",
    "# 선택된 인덱스로 데이터프레임 업데이트\n",
    "stock_data = stock_data.iloc[selected_indices]\n",
    "\n",
    "# 거래량을 정규화할 컬럼 선택\n",
    "volume_column = ['Volume']\n",
    "\n",
    "# 거래량 컬럼을 정규화\n",
    "stock_data[volume_column] = scaler.fit_transform(stock_data[volume_column])\n",
    "\n",
    "# 상한가, 하한가를 넘어서게 변화한 데이터 삭제\n",
    "stock_data = stock_data[(stock_data['Change'] >= -0.3) & (stock_data['Change'] <= 0.3)]\n",
    "\n",
    "# 정규화된 데이터 출력\n",
    "print(stock_data)\n",
    "\n",
    "# # CSV 파일로 저장할 경로와 파일 이름 정의\n",
    "# output_file = '15_20_066570.csv'\n",
    "\n",
    "# # 정규화된 데이터프레임을 CSV 파일로 저장\n",
    "# stock_data.to_csv(output_file, index=False)\n",
    "\n",
    "# print(f'정규화된 주식 데이터를 {output_file} 파일로 저장했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.10316925 0.09885676 0.09414226 ... 0.31771928 0.61392405 0.1039604 ]]\n",
      "\n",
      " [[0.16250843 0.16341627 0.16317992 ... 0.22286554 0.58227848 0.08910891]]\n",
      "\n",
      " [[0.20161834 0.20511096 0.19804742 ... 0.15101879 0.44303797 0.14851485]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.19892111 0.19300605 0.19525802 ... 0.13566702 0.51476793 0.07920792]]\n",
      "\n",
      " [[0.22454484 0.21452589 0.22315202 ... 0.13700715 0.45147679 0.03960396]]\n",
      "\n",
      " [[0.75859744 0.78480161 0.77405858 ... 0.61562411 0.82278481 0.32673267]]]\n",
      "[[[0.52124073 0.5198386  0.53138075 ... 0.19498188 0.61181435 0.0990099 ]]\n",
      "\n",
      " [[0.3054619  0.30598521 0.31380753 ... 0.2216254  0.26582278 0.06930693]]\n",
      "\n",
      " [[0.33108564 0.32078009 0.31799163 ... 0.20215167 0.47679325 0.14851485]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.09710047 0.10154674 0.09902371 ... 0.27567456 0.33755274 0.08910891]]\n",
      "\n",
      " [[0.15576534 0.16341627 0.15620642 ... 0.40855983 0.46413502 0.13861386]]\n",
      "\n",
      " [[0.85839514 0.84532616 0.85355649 ... 0.12460478 0.46835443 0.20792079]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# (위에서 주신 데이터 및 전처리 과정 사용)\n",
    "\n",
    "# 데이터를 입력(X)와 출력(y)로 분할\n",
    "X = stock_data.drop('Close', axis=1).values  # 종가를 제외한 모든 특성을 입력으로 사용\n",
    "y = stock_data['Close'].values  # 종가를 출력으로 사용\n",
    "\n",
    "# 학습 및 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터를 3D 형태로 변환 (samples, timesteps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3278938477.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\SSAFY\\AppData\\Local\\Temp\\ipykernel_21920\\3278938477.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    model.add(Dense(1, activation='linear'))\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class StockModelEnsemble:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, input_shape=(1, self.X_train.shape[2]))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(self.X_train, self.y_train, epochs=50, batch_size=32, validation_data=(self.X_test, self.y_test))\n",
    "        return model\n",
    "\n",
    "    def build_dnn_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_shape=(1, self.X_train.shape[2]), activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(self.X_train, self.y_train, epochs=50, batch_size=32, validation_data=(self.X_test, self.y_test))\n",
    "        return model\n",
    "\n",
    "    def build_cnn_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, self.X_train.shape[2]))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(self.X_train, self.y_train, epochs=50, batch_size=32, validation_data=(self.X_test, self.y_test))\n",
    "        return model\n",
    "\n",
    "    def predict(self, model, X):\n",
    "        return model.predict(X)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "stock_ensemble = StockModelEnsemble(X_train, y_train, X_test, y_test)\n",
    "lstm_model = stock_ensemble.build_lstm_model()\n",
    "dnn_model = stock_ensemble.build_dnn_model()\n",
    "cnn_model = stock_ensemble.build_cnn_model()\n",
    "\n",
    "# 각 모델로 예측 생성\n",
    "lstm_predictions = stock_ensemble.predict(lstm_model, X_test)\n",
    "dnn_predictions = stock_ensemble.predict(dnn_model, X_test)\n",
    "cnn_predictions = stock_ensemble.predict(cnn_model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EnsembleModel:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 모든 모델의 예측을 생성\n",
    "        predictions = [model.predict(X) for model in self.models]\n",
    "        # 예측을 평균\n",
    "        ensemble_predictions = np.mean(predictions, axis=0)\n",
    "        return ensemble_predictions\n",
    "\n",
    "# 모든 모델을 리스트에 넣어서 앙상블 모델을 생성\n",
    "models = [lstm_model, dnn_model, cnn_model]\n",
    "ensemble = EnsembleModel(models)\n",
    "\n",
    "# 테스트 데이터로 앙상블 모델의 예측 생성\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "ensemble_predictions = ensemble.predict(X_test_reshaped)\n",
    "\n",
    "# 평균 앙상블의 예측 결과 출력\n",
    "print(ensemble_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
